{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Ak4If2D-6M",
        "outputId": "0b40cdf5-6652-4ae2-e18a-b1086d54ed2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load nn.py"
      ],
      "metadata": {
        "id": "8KraeMgbELz0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('nn.py', 'r') as file:\n",
        "    code = file.read()"
      ],
      "metadata": {
        "id": "GMDGVG7wEL81"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tUHxeRREMF7",
        "outputId": "6d2db2b7-65be-4e9e-8444-1a8342cf5d37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# -*- coding: utf-8 -*-\n",
            "\"\"\"nn.ipynb\n",
            "\n",
            "Automatically generated by Colaboratory.\n",
            "\n",
            "Original file is located at\n",
            "    https://colab.research.google.com/drive/1LealFOZf0ukDp7e0dJ5PrtFUeVRgNYtd\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "\n",
            "\"\"\"\n",
            "The main code for the recurrent and convolutional networks assignment.\n",
            "See README.md for details.\n",
            "\"\"\"\n",
            "from typing import Tuple, List, Dict\n",
            "\n",
            "import tensorflow\n",
            "\n",
            "\n",
            "def create_toy_rnn(input_shape: tuple, n_outputs: int) \\\n",
            "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
            "    \"\"\"Creates a recurrent neural network for a toy problem.\n",
            "\n",
            "    The network will take as input a sequence of number pairs, (x_{t}, y_{t}),\n",
            "    where t is the time step. It must learn to produce x_{t-3} - y{t} as the\n",
            "    output of time step t.\n",
            "\n",
            "    This method does not call Model.fit, but the dictionary it returns alongside\n",
            "    the model will be passed as extra arguments whenever Model.fit is called.\n",
            "    This can be used to, for example, set the batch size or use early stopping.\n",
            "\n",
            "    :param input_shape: The shape of the inputs to the model.\n",
            "    :param n_outputs: The number of outputs from the model.\n",
            "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
            "    \"\"\"\n",
            "    inputs = tensorflow.keras.Input(shape=input_shape)\n",
            "    rnn = tensorflow.keras.layers.SimpleRNN(200, return_sequences=True)\n",
            "    outputs = tensorflow.keras.layers.Dense(n_outputs)\n",
            "    model = tensorflow.keras.models.Model(inputs=inputs,\n",
            "                                          outputs=outputs(rnn(inputs)))\n",
            "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
            "    return model, dict(batch_size=1)\n",
            "\n",
            "\n",
            "def create_mnist_cnn(input_shape: tuple, n_outputs: int) \\\n",
            "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
            "    \"\"\"Creates a convolutional neural network for digit classification.\n",
            "\n",
            "    The network will take as input a 28x28 grayscale image, and produce as\n",
            "    output one of the digits 0 through 9. The network will be trained and tested\n",
            "    on a fraction of the MNIST data: http://yann.lecun.com/exdb/mnist/\n",
            "\n",
            "    This method does not call Model.fit, but the dictionary it returns alongside\n",
            "    the model will be passed as extra arguments whenever Model.fit is called.\n",
            "    This can be used to, for example, set the batch size or use early stopping.\n",
            "\n",
            "    :param input_shape: The shape of the inputs to the model.\n",
            "    :param n_outputs: The number of outputs from the model.\n",
            "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
            "    \"\"\"\n",
            "    model = tensorflow.keras.models.Sequential()\n",
            "    model.add(tensorflow.keras.layers.Conv2D(\n",
            "        64, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
            "    model.add(tensorflow.keras.layers.Conv2D(\n",
            "        64, kernel_size=(2, 2), activation='relu', input_shape=input_shape))\n",
            "    model.add(tensorflow.keras.layers.Flatten())\n",
            "    model.add(tensorflow.keras.layers.Dense(\n",
            "        n_outputs, activation='softmax'))\n",
            "    model.compile(loss=\"CategoricalCrossentropy\", optimizer=\"adam\")\n",
            "    return model, {}\n",
            "\n",
            "\n",
            "def create_youtube_comment_rnn(vocabulary: List[str], n_outputs: int) \\\n",
            "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
            "    \"\"\"Creates a recurrent neural network for spam classification.\n",
            "\n",
            "    This network will take as input a YouTube comment, and produce as output\n",
            "    either 1, for spam, or 0, for ham (non-spam). The network will be trained\n",
            "    and tested on data from:\n",
            "    https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection\n",
            "\n",
            "    Each comment is represented as a series of tokens, with each token\n",
            "    represented by a number, which is its index in the vocabulary. Note that\n",
            "    comments may be of variable length, so in the input matrix, comments with\n",
            "    fewer tokens than the matrix width will be right-padded with zeros.\n",
            "\n",
            "    This method does not call Model.fit, but the dictionary it returns alongside\n",
            "    the model will be passed as extra arguments whenever Model.fit is called.\n",
            "    This can be used to, for example, set the batch size or use early stopping.\n",
            "\n",
            "    :param vocabulary: The vocabulary defining token indexes.\n",
            "    :param n_outputs: The number of outputs from the model.\n",
            "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
            "    \"\"\"\n",
            "    model = tensorflow.keras.models.Sequential([\n",
            "        tensorflow.keras.layers.Embedding(len(vocabulary), 8, mask_zero=True),\n",
            "        tensorflow.keras.layers.Bidirectional(tensorflow.keras.layers.LSTM(8)),\n",
            "        tensorflow.keras.layers.Dense(n_outputs, activation='sigmoid'),\n",
            "    ])\n",
            "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
            "    return model, {}\n",
            "\n",
            "\n",
            "def create_youtube_comment_cnn(vocabulary: List[str], n_outputs: int) \\\n",
            "        -> Tuple[tensorflow.keras.models.Model, Dict]:\n",
            "    \"\"\"Creates a convolutional neural network for spam classification.\n",
            "\n",
            "    This network will take as input a YouTube comment, and produce as output\n",
            "    either 1, for spam, or 0, for ham (non-spam). The network will be trained\n",
            "    and tested on data from:\n",
            "    https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection\n",
            "\n",
            "    Each comment is represented as a series of tokens, with each token\n",
            "    represented by a number, which is its index in the vocabulary. Note that\n",
            "    comments may be of variable length, so in the input matrix, comments with\n",
            "    fewer tokens than the matrix width will be right-padded with zeros.\n",
            "\n",
            "    This method does not call Model.fit, but the dictionary it returns alongside\n",
            "    the model will be passed as extra arguments whenever Model.fit is called.\n",
            "    This can be used to, for example, set the batch size or use early stopping.\n",
            "\n",
            "    :param vocabulary: The vocabulary defining token indexes.\n",
            "    :param n_outputs: The number of outputs from the model.\n",
            "    :return: A tuple of (neural network, Model.fit keyword arguments)\n",
            "    \"\"\"\n",
            "    inputs = tensorflow.keras.Input(shape=(None,))\n",
            "    embed = tensorflow.keras.layers.Embedding(len(vocabulary), 64)\n",
            "    conv = tensorflow.keras.layers.Conv1D(64, kernel_size=5, activation='relu')\n",
            "    pool = tensorflow.keras.layers.GlobalMaxPooling1D()\n",
            "    outputs = tensorflow.keras.layers.Dense(n_outputs, activation='sigmoid')\n",
            "    model = tensorflow.keras.models.Model(\n",
            "        inputs=inputs, outputs=outputs(pool(conv(embed(inputs)))))\n",
            "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
            "    return model, {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load test_nn.py"
      ],
      "metadata": {
        "id": "PMsdZXk3EMJ9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPV8uEa_EMNt",
        "outputId": "15d274d8-3945-4583-91c4-08591122c01d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.4, pluggy-1.4.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 4 items                                                                                  \u001b[0m\n",
            "\n",
            "test_nn.py \n",
            "0.6 RMSE for RNN on toy problem\n",
            "\u001b[32m.\u001b[0m\n",
            "90.0% accuracy for CNN on MNIST sample\n",
            "\u001b[32m.\u001b[0m\n",
            "90.5% accuracy for RNN on Youtube comments\n",
            "\u001b[32m.\u001b[0m\n",
            "84.3% accuracy for CNN on Youtube comments\n",
            "\u001b[32m.\u001b[0m\u001b[32m                                                                              [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 102.80s (0:01:42)\u001b[0m\u001b[32m ===================================\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}